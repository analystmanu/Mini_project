{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'movies'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.977498Z",
     "iopub.status.busy": "2022-03-11T13:19:25.977059Z",
     "iopub.status.idle": "2022-03-11T13:19:25.981746Z",
     "shell.execute_reply": "2022-03-11T13:19:25.980719Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.977465Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use output of OpenPose without background\n",
    "# Paths to videos for training\n",
    "PATHS = [f\"../datasets/{DATASET}_dataset/original_data/\", f\"../datasets/{DATASET}_dataset/openpose_gamma/\"]\n",
    "\n",
    "FRAME_FUNC = 'frame_diff'\n",
    "# To use frame diff to weight t (current) or t+1\n",
    "WEIGHT_CURRENT = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.98401Z",
     "iopub.status.busy": "2022-03-11T13:19:25.983753Z",
     "iopub.status.idle": "2022-03-11T13:19:25.991894Z",
     "shell.execute_reply": "2022-03-11T13:19:25.991105Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.983972Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 19:28:31.819275: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.821660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.825402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.831963: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.833286: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.835267: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.835745: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.837014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:31.839002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "!export TF_FORCE_GPU_ALLOW_GROWTH=True\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    tf.config.set_visible_devices(gpus[1:], 'GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:25.99373Z",
     "iopub.status.busy": "2022-03-11T13:19:25.993435Z",
     "iopub.status.idle": "2022-03-11T13:19:26.016866Z",
     "shell.execute_reply": "2022-03-11T13:19:26.016121Z",
     "shell.execute_reply.started": "2022-03-11T13:19:25.993694Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.020522Z",
     "iopub.status.busy": "2022-03-11T13:19:26.019963Z",
     "iopub.status.idle": "2022-03-11T13:19:26.026099Z",
     "shell.execute_reply": "2022-03-11T13:19:26.025371Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.020483Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.029742Z",
     "iopub.status.busy": "2022-03-11T13:19:26.029354Z",
     "iopub.status.idle": "2022-03-11T13:19:26.044202Z",
     "shell.execute_reply": "2022-03-11T13:19:26.042228Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.029704Z"
    }
   },
   "outputs": [],
   "source": [
    "FRAMES_PER_VIDEO = 50 + 1\n",
    "VIDEO_WIDTH, VIDEO_HEIGHT = 100, 100\n",
    "N_CHANNELS = 3\n",
    "\n",
    "def load_videos(video_IDs: list, video_frames: int = FRAMES_PER_VIDEO, video_width: int = VIDEO_WIDTH, video_height: int = VIDEO_HEIGHT,\n",
    "                video_channels: int = N_CHANNELS, dtype = np.float32, normalize: bool = False) -> tuple:\n",
    "    videos = np.empty((len(video_IDs), video_frames, video_height, video_width, video_channels), dtype=dtype)\n",
    "\n",
    "    for i, video_ID in enumerate(video_IDs):\n",
    "        cap = cv2.VideoCapture(video_ID)\n",
    "        original_n_frames = int(cap. get(cv2. CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Indexes of frames to be kept to comply with video_frames\n",
    "        frames_idx = set(np.round(np.linspace(0, original_n_frames - 1, video_frames)).astype(int))\n",
    "\n",
    "        frames = []\n",
    "        index = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            if index in frames_idx:\n",
    "                frame = cv2.resize(frame, (video_width, video_height)).astype(dtype)\n",
    "                if normalize:\n",
    "                    frame /= 255.0\n",
    "                frames.append(frame)\n",
    "            index += 1\n",
    "        cap.release()\n",
    "\n",
    "        if len(frames) != video_frames:\n",
    "            # Complete with repeated frames in the begging and the end of the video\n",
    "            n_repeats = (video_frames - len(frames)) / 2\n",
    "            # In case n_repeats is decimal, first frames will be rounded to the nearest integer\n",
    "            beggining_frames = np.tile(frames[0], [round(n_repeats + 0.001), 1, 1, 1])\n",
    "            end_frames = np.tile(frames[-1], [int(n_repeats), 1, 1, 1])\n",
    "            frames = np.concatenate([beggining_frames, frames, end_frames])\n",
    "        \n",
    "        videos[i,] = np.array(frames)\n",
    "        \n",
    "\n",
    "    return videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataGenerator class to load videos per batch, in case all videos do not fit in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.045807Z",
     "iopub.status.busy": "2022-03-11T13:19:26.045605Z",
     "iopub.status.idle": "2022-03-11T13:19:26.059732Z",
     "shell.execute_reply": "2022-03-11T13:19:26.058897Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.045781Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, video_IDs: list, video_labels: list, batch_size: int, paths: list = [''], video_width: int = VIDEO_WIDTH, video_height: int = VIDEO_HEIGHT,\n",
    "                video_frames: int = FRAMES_PER_VIDEO, video_channels: int = N_CHANNELS, dtype = np.float32, normalize: bool = False, shuffle: bool = True):\n",
    "        self.video_IDs = video_IDs\n",
    "        self.video_labels = video_labels\n",
    "        self.batch_size = batch_size\n",
    "        self.paths = paths\n",
    "        self.video_width = video_width\n",
    "        self.video_height = video_height\n",
    "        self.video_frames = video_frames\n",
    "        self.video_channels = video_channels\n",
    "        self.dtype = dtype\n",
    "        self.normalize = normalize\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.video_IDs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_IDs = self.video_IDs[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_labels = self.video_labels[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        input_videos = []\n",
    "        \n",
    "        for index, path in enumerate(self.paths):\n",
    "            batch_IDs_full_path = [path+ID for ID in batch_IDs]\n",
    "\n",
    "            videos = load_videos(batch_IDs_full_path, self.video_frames, self.video_width, \n",
    "                                         self.video_height, self.video_channels, self.dtype, self.normalize)\n",
    "            \n",
    "            input_videos.append(videos)\n",
    "                    \n",
    "        return input_videos, batch_labels\n",
    "            \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        if self.shuffle:\n",
    "            # shuffle video_IDs and video_labels together\n",
    "            temp_list = list(zip(self.video_IDs, self.video_labels))\n",
    "            np.random.shuffle(temp_list)\n",
    "            self.video_IDs, self.video_labels = zip(*temp_list)\n",
    "        # Clear memory after epochs\n",
    "        gc.collect()\n",
    "        #K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Videos to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-11T13:19:26.062131Z",
     "iopub.status.busy": "2022-03-11T13:19:26.06193Z",
     "iopub.status.idle": "2022-03-11T13:19:26.085657Z",
     "shell.execute_reply": "2022-03-11T13:19:26.084932Z",
     "shell.execute_reply.started": "2022-03-11T13:19:26.062105Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "folds = pd.read_csv(f'../datasets/{DATASET}_dataset/folds.csv')\n",
    "\n",
    "def fecth_generators(fold):\n",
    "\n",
    "    train_df = folds[folds.fold != fold]\n",
    "    test_df = folds[folds.fold == fold]\n",
    "\n",
    "    train_video_IDs = train_df.video.values\n",
    "    test_video_IDs = test_df.video.values\n",
    "\n",
    "    train_video_labels = train_df.label.values\n",
    "    test_video_labels = test_df.label.values\n",
    "\n",
    "    train_generator = DataGenerator(train_video_IDs, train_video_labels, batch_size=10, paths=PATHS)\n",
    "    test_generator = DataGenerator(test_video_IDs, test_video_labels, batch_size=10, paths=PATHS)\n",
    "\n",
    "    return train_generator, test_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "\n",
    "def tf_frame_diff(video):\n",
    "    return video[1:] - video[:-1]\n",
    "\n",
    "frame_func = tf_frame_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pretrained best model without optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## Fold 0 ##########\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 19:28:31.940254: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-25 19:28:32.107082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.109073: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.109519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.111459: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.111890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.113821: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.686662: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.688702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.689210: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.691165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.691613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.693559: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 75367 MB memory:  -> device: 1, name: NVIDIA A100 80GB PCIe, pci bus id: 0000:61:00.0, compute capability: 8.0\n",
      "2022-07-25 19:28:32.693859: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-25 19:28:32.694274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 2284 MB memory:  -> device: 2, name: NVIDIA T1000, pci bus id: 0000:41:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 19:28:37.635596: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8204\n",
      "2022-07-25 19:28:38.318131: W tensorflow/stream_executor/gpu/asm_compiler.cc:111] *** WARNING *** You are using ptxas 10.1.243, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "You may not need to update to CUDA 11.1; cherry-picking the ptxas binary is often sufficient.\n",
      "2022-07-25 19:28:38.320197: W tensorflow/stream_executor/gpu/asm_compiler.cc:230] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.0\n",
      "2022-07-25 19:28:38.320231: W tensorflow/stream_executor/gpu/asm_compiler.cc:233] Used ptxas at ptxas\n",
      "2022-07-25 19:28:38.320366: W tensorflow/stream_executor/gpu/redzone_allocator.cc:314] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2022-07-25 19:28:39.168288: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 - 20s - loss: 0.7316 - accuracy: 0.7500 - val_loss: 0.6579 - val_accuracy: 0.7000 - 20s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "16/16 - 14s - loss: 0.3452 - accuracy: 0.8687 - val_loss: 0.4639 - val_accuracy: 0.9250 - 14s/epoch - 896ms/step\n",
      "Epoch 3/5\n",
      "16/16 - 14s - loss: 0.2147 - accuracy: 0.9312 - val_loss: 0.3359 - val_accuracy: 0.9250 - 14s/epoch - 903ms/step\n",
      "Epoch 4/5\n",
      "16/16 - 14s - loss: 0.1728 - accuracy: 0.9625 - val_loss: 0.3437 - val_accuracy: 0.9500 - 14s/epoch - 898ms/step\n",
      "Epoch 5/5\n",
      "16/16 - 14s - loss: 0.1435 - accuracy: 0.9688 - val_loss: 0.3046 - val_accuracy: 0.9000 - 14s/epoch - 894ms/step\n",
      "########## Fold 0 accuracy: 0.949999988079071 ##########\n",
      "########## Fold 1 ##########\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/5\n",
      "16/16 - 18s - loss: 0.6175 - accuracy: 0.7188 - val_loss: 0.6466 - val_accuracy: 0.8250 - 18s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "16/16 - 14s - loss: 0.2916 - accuracy: 0.8938 - val_loss: 0.5507 - val_accuracy: 0.8500 - 14s/epoch - 897ms/step\n",
      "Epoch 3/5\n",
      "16/16 - 14s - loss: 0.1750 - accuracy: 0.9500 - val_loss: 0.5134 - val_accuracy: 0.8750 - 14s/epoch - 893ms/step\n",
      "Epoch 4/5\n",
      "16/16 - 14s - loss: 0.1410 - accuracy: 0.9563 - val_loss: 0.4954 - val_accuracy: 0.9000 - 14s/epoch - 902ms/step\n",
      "Epoch 5/5\n",
      "16/16 - 14s - loss: 0.1165 - accuracy: 0.9750 - val_loss: 0.4960 - val_accuracy: 0.8750 - 14s/epoch - 900ms/step\n",
      "########## Fold 1 accuracy: 0.8999999761581421 ##########\n",
      "########## Fold 2 ##########\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/5\n",
      "16/16 - 18s - loss: 0.6606 - accuracy: 0.7875 - val_loss: 0.6184 - val_accuracy: 0.6750 - 18s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "16/16 - 14s - loss: 0.3754 - accuracy: 0.8875 - val_loss: 0.3418 - val_accuracy: 0.8000 - 14s/epoch - 898ms/step\n",
      "Epoch 3/5\n",
      "16/16 - 14s - loss: 0.2414 - accuracy: 0.9375 - val_loss: 0.2002 - val_accuracy: 0.9500 - 14s/epoch - 902ms/step\n",
      "Epoch 4/5\n",
      "16/16 - 14s - loss: 0.1996 - accuracy: 0.9500 - val_loss: 0.1510 - val_accuracy: 0.9500 - 14s/epoch - 895ms/step\n",
      "Epoch 5/5\n",
      "16/16 - 14s - loss: 0.1797 - accuracy: 0.9688 - val_loss: 0.1241 - val_accuracy: 0.9750 - 14s/epoch - 901ms/step\n",
      "########## Fold 2 accuracy: 0.9750000238418579 ##########\n",
      "########## Fold 3 ##########\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/5\n",
      "16/16 - 18s - loss: 0.6796 - accuracy: 0.7625 - val_loss: 0.2113 - val_accuracy: 0.8750 - 18s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "16/16 - 14s - loss: 0.3460 - accuracy: 0.8875 - val_loss: 0.1353 - val_accuracy: 0.9500 - 14s/epoch - 899ms/step\n",
      "Epoch 3/5\n",
      "16/16 - 14s - loss: 0.2769 - accuracy: 0.9250 - val_loss: 0.0711 - val_accuracy: 1.0000 - 14s/epoch - 905ms/step\n",
      "Epoch 4/5\n",
      "16/16 - 14s - loss: 0.2090 - accuracy: 0.9438 - val_loss: 0.0563 - val_accuracy: 1.0000 - 14s/epoch - 896ms/step\n",
      "Epoch 5/5\n",
      "16/16 - 14s - loss: 0.1833 - accuracy: 0.9438 - val_loss: 0.0774 - val_accuracy: 1.0000 - 14s/epoch - 899ms/step\n",
      "########## Fold 3 accuracy: 1.0 ##########\n",
      "########## Fold 4 ##########\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Epoch 1/5\n",
      "16/16 - 18s - loss: 0.6428 - accuracy: 0.7937 - val_loss: 0.3705 - val_accuracy: 0.7750 - 18s/epoch - 1s/step\n",
      "Epoch 2/5\n",
      "16/16 - 14s - loss: 0.3131 - accuracy: 0.9125 - val_loss: 0.2147 - val_accuracy: 0.9000 - 14s/epoch - 902ms/step\n",
      "Epoch 3/5\n",
      "16/16 - 14s - loss: 0.2358 - accuracy: 0.9375 - val_loss: 0.1605 - val_accuracy: 0.9250 - 14s/epoch - 897ms/step\n",
      "Epoch 4/5\n",
      "16/16 - 14s - loss: 0.1774 - accuracy: 0.9500 - val_loss: 0.1526 - val_accuracy: 0.9500 - 14s/epoch - 898ms/step\n",
      "Epoch 5/5\n",
      "16/16 - 14s - loss: 0.1511 - accuracy: 0.9688 - val_loss: 0.1423 - val_accuracy: 0.9500 - 14s/epoch - 898ms/step\n",
      "########## Fold 4 accuracy: 0.949999988079071 ##########\n"
     ]
    }
   ],
   "source": [
    "cv_acc = 0.0\n",
    "\n",
    "for fold in range(5):\n",
    "    print('#'*10, 'Fold', fold, '#'*10)\n",
    "\n",
    "    model = tf.keras.models.load_model('models/rwf_best_model_no_optimizer.h5')\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f'models/{DATASET}_best_model_fold{fold}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        save_best_only=True)\n",
    "\n",
    "    train_generator, test_generator = fecth_generators(fold)\n",
    "    history = model.fit(train_generator, epochs=5, validation_data=test_generator, verbose=2, callbacks=[model_checkpoint_callback])\n",
    "\n",
    "    fold_acc = max(history.history['val_accuracy'])\n",
    "    print('#'*10, f'Fold {fold} accuracy:', fold_acc, '#'*10)\n",
    "    cv_acc += fold_acc / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.9549999952316284\n"
     ]
    }
   ],
   "source": [
    "print('CV accuracy:', cv_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg-info-env",
   "language": "python",
   "name": "tfg-info-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
